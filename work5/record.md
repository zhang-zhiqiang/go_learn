#### 隔离
隔离，本质上是对系统或资源进行分割，从而实现当系统发生故障时能限定传播范围和影响范围，即发生故障后只有出问题的服务不可用，保障其他服务仍然可用。

服务隔离
* 动静分离、读写分离

轻重隔离
* 核心、快慢、热点

物理隔离
* 线程、进程、集群、机房


##### 动静隔离
小到 CPU 的 cacheline false sharing、数据库 mysql 表设计中避免 bufferpool 频繁过期，隔离动静表，大到架构设计中的图片、静态资源等缓存加速。本质上都体现的一样的思路，即加速/缓存访问变换频次小的。比如 CDN 场景中，将静态资源和动态 API 分离，也是体现了隔离的思路：

* 降低应用服务器负载，静态文件访问负载全部通过CDN。
* 对象存储存储费用最低。
* 海量存储空间，无需考虑存储架构升级。
* 静态CDN带宽加速，延迟低。

##### 轻重隔离（核心隔离）
业务按照 Level 进行资源池划分(L0/L1/L2)
* 核心/非核心的故障域的差异隔离（机器隔离、依赖资源）。
* 多集群，通过冗余资源来提高吞吐和容载能力

##### 快慢隔离
我们可以把服务的吞吐想象为一个池，当突然洪流进来时，池子需要一定时间才能排放完，这时候其他洪流在池子里待的实践取决于前面的排放能力，耗时就会增高，对小请求产生影响。

##### 热点隔离
热点即经常访问的数据。很多时候我们希望统计某个热点数据中访问频次最高的 Top K 数据，并对其访问进行缓存。

##### 进程隔离
容器化(docker)，容器编排引擎（k8s）。

##### 集群隔离
gRPC，多集群方案，即逻辑上是一个应用，物理上部署多套应用，通过 cluster 区分。

---

#### 超时控制
超时控制，我们的组件能够快速失败(fail fast)，因为我们不希望等到断开的实例直到超时。没有什么比挂起的请求和无响应的界面更令人失望。这不仅浪费资源，而且还会让用户体验变得更差。我们的服务是互相调用的，所以在这些延迟叠加前，应该特别防止那些超时的操作。
* 网络传递具有不确定性
* 客户端和服务端不一致的超时策略导致资源浪费
* “默认值” 策略
* 高延迟服务导致 client 浪费资源等待，使用超时传递：进程间传递 + 跨进程传递。

超时控制是为服务可用性的第一道关，良好的超时策略，可以尽可能让服务不堆积请求，尽快清空高延迟的请求，释放 Goroutine。

##### 如何做超时控制
* 服务提供者定义好 latency SLO，更新到 gRPC Proto 定义中，服务后续迭代，都应保证 SLO。
* kit 基础库兜底默认超时，比如 100ms，进行配置防御保护，避免出现类似 60s 之类的超大超时策略。
* 配置中心公共模版，对于未配置的服务使用公共配置。

##### 超时传递
当上游服务已经超时返回504，但下游服务仍然在执行，会导致浪费资源做无用功。超时传递指的是把当前服务的剩余 Quota 传递到下游服务中，继承超时策略，控制请求级别的全局超时控制。
* 进程内超时控制
  一个请求在每个阶段（网络请求）开始前，就要检查是否还有足够的剩余来处理请求，以及继承他的超时策略，使用 Go 标准库的 context.WithTimeout

* 双峰分布：95% 的请求耗时在100ms内，5%的请求可能永远不会完成（长超时）
* 对于监控不要只看 mean， 可以看看耗时分布统计，比如 95th， 99th。
* 设置合理的超时，拒绝超长请求，或者当 Server 不可用要主动失败。

超时决定着服务线程耗尽

---

#### 过载保护
##### 令牌桶 /k/time/rate
是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。
* 假设限制2r/s ，则按照 500 毫秒 的固定速率往桶中添加令牌。
* 桶中最多存放 b 个令牌，当桶满时，新添加的令牌被丢弃或拒绝。
* 当一个 n 个字节大小的数据包到达，将从桶中删除 n 个令牌，接着数据包被发送到网络上。
* 如果桶中的令牌不足 n 个，则不会删除令牌，则该数据包将被限流（要么丢弃，要么缓冲区等待）

##### 漏桶算法
作为计量工具，可以用于流量整形和流量控制，
* 一个固定容量的漏桶，按照常量固定速率流出水滴
* 如果桶是空的，则不需流出水滴
* 可以以任意速率流入水滴到漏桶
* 如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），则漏桶容量是不变的

##### 过载保护
计算系统临近过载时的峰值吞吐作为限流的阀值来进行流量控制，达到系统保护。
* 服务器临近过载时，主动抛弃一定量的负载，目标是自保
* 在系统稳定的前提下，保持系统的吞吐量

###### 常见做法： 科特尔法则
* CPU、内存作为信号量进行限流
* 队列管理：队列长度、LIFO
* 可控延迟算法：CoDel

---

#### 限流
限流是指在一段时间内，定义某个客户或应用可以接收或处理多少个请求的技术。例如：通过限流可以过滤掉产生流量峰值的客户或微服务，或者可以确保你的应用程序在自动扩展（Auto Scaling）失效前都不会出现过载的情况。
* 令牌桶、漏桶 针对单个节点，无法分布式限流。
* QPS 限流
* 1。 不同的请求可能需要数量迥异的资源来处理
* 2。 某种静态 QPS 限流不是特别准
* 给每个用户设置限制
* 全局过载发生时候，针对某些“异常”进行控制
* 一定程度的“超卖”配额
* 按照优先级丢弃
* 拒绝请求也需要成本。

##### 分布式限流，是为了控制某个应用全局的流量，而非针对某个节点维度
* 单个大流量的接口，使用 redis 容易产生热点
* pre-request 模式对性能有一定影响，高频的网络往返

##### 资源分配：最大最小公平分享
* 资源按照需求递增的顺序进行分配
* 不存在用户得到的资源超过自己的需求
* 未得到满足的用户等价的分享资源

---

#### 熔断
* 服务依赖的资源出现大量错误
* 当某个用户超过资源配额时，后端任务会快速拒绝请求，返回“配额不足”的错误，但是拒绝回复仍然后消耗一定资源。有可能后端忙着不停发送拒绝请求，导致过载。


#### 降级
通过降级回复来减少工作量，或者丢弃不重要的请求。
* 确定具体采用哪个指标作为流量评估和优雅降级的决定性指标（如， CPU、延迟、队列长度、线程数量、报错）
* 当服务进入降级模式时，需要执行那些动作
* 流量抛弃或者优雅降级应该在服务的哪一层实现？是否需要在整个服务的每一层都实现，还是可以选择某个高层面的关键节点来实现？

#### 重试
当请求返回错误（例：配额不足、超时、内部错误等）对于backend 部分节点过载的情况下，倾向于立刻重试，但是需要留意重试带来的流量放大：
* 限制重试次数和基于重试分布的策略（充实比率：10%）
* 随机化、指数型递增的重试周期：exponential backoff + jitter
* client 测记录重拾次数直方图，传递到 server，进行分布判定，交由 server 判断拒绝
* 只应该再失败的这层进行重试，当重试仍然失败，全局约定错误码“过载、无须”，避免级联重试

#### 负载均衡
* 均衡的流量分发
* 可靠的识别异常节点
* scale-out，增加同治节点扩容
* 减少错误，提高可用性

###### 变更管理
70% 的问题是由变更引起的，恢复可用代码不总是坏事
###### 避免过载
过载保护、流量调度
###### 依赖管理
任何依赖都可能故障，做 chaos monkey testing，注入故障测试
###### 优雅降级
有损服务，避免核心链路依赖故障
###### 重试退避
退让算法，冻结时间，API retry detail 控制策略
###### 超时控制
进程内 + 服务间 超时控制。
###### 极限压测 + 故障演练
###### 扩容 + 重启 + 消除有害流量

